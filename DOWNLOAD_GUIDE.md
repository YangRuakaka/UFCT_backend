# ä½¿ç”¨ Hugging Face API ä¸‹è½½æ•°æ®

## æ–¹æ¡ˆ 1: ä½¿ç”¨æ–°çš„ API ä¸‹è½½è„šæœ¬ï¼ˆæŽ¨èï¼‰

### æ­¥éª¤ 1: è®¾ç½® HF_TOKEN çŽ¯å¢ƒå˜é‡

#### Windows (cmd):
```batch
set HF_TOKEN=your_huggingface_token_here
python download_dataset_api.py
```

#### Windows (PowerShell):
```powershell
$env:HF_TOKEN="your_huggingface_token_here"
python download_dataset_api.py
```

#### Linux/Mac:
```bash
export HF_TOKEN=your_huggingface_token_here
python download_dataset_api.py
```

### æ­¥éª¤ 2: èŽ·å– HF_TOKEN

1. è®¿é—® https://huggingface.co/settings/tokens
2. åˆ›å»ºæ–°çš„è®¿é—®ä»¤ç‰Œï¼ˆTokenï¼‰
3. å¤åˆ¶ä»¤ç‰Œå€¼

### æ­¥éª¤ 3: æŸ¥çœ‹ä¸‹è½½è¿›åº¦

è„šæœ¬ä¼šæ˜¾ç¤ºï¼š
- âœ“ å¯ç”¨çš„æ•°æ® splits
- âœ“ Parquet æ–‡ä»¶åˆ—è¡¨
- ðŸ“Š é€ä¸ªä¸‹è½½è¿›åº¦æ¡
- âœ“ æœ€åŽçš„å®Œæˆç»Ÿè®¡

## æ–¹æ¡ˆ 2: ä½¿ç”¨ curl å‘½ä»¤ç›´æŽ¥ä¸‹è½½

### æŸ¥çœ‹å¯ç”¨çš„ splits:
```bash
curl -X GET \
  -H "Authorization: Bearer $HF_TOKEN" \
  "https://datasets-server.huggingface.co/splits?dataset=Northwestern-CSSI%2Fsciscinet-v2"
```

### èŽ·å– Parquet æ–‡ä»¶åˆ—è¡¨:
```bash
curl -X GET \
  -H "Authorization: Bearer $HF_TOKEN" \
  "https://huggingface.co/api/datasets/Northwestern-CSSI/sciscinet-v2/parquet/default"
```

### èŽ·å–ç‰¹å®šè¡Œæ•°æ®:
```bash
curl -X GET \
  -H "Authorization: Bearer $HF_TOKEN" \
  "https://datasets-server.huggingface.co/rows?dataset=Northwestern-CSSI%2Fsciscinet-v2&config=default&split=train&offset=0&length=100"
```

## æ•°æ®æ–‡ä»¶è¯´æ˜Ž

SciSciNet-v2 åŒ…å«ä»¥ä¸‹ä¸»è¦ Parquet æ–‡ä»¶ï¼š

- `hit_papers_level0.parquet` - è®ºæ–‡åŸºç¡€ä¿¡æ¯ï¼ˆçº§åˆ«0ï¼‰
- `hit_papers_level1.parquet` - è®ºæ–‡è¯¦ç»†ä¿¡æ¯ï¼ˆçº§åˆ«1ï¼‰
- `normalized_citations_level0.parquet` - å¼•ç”¨å…³ç³»ï¼ˆçº§åˆ«0ï¼‰
- `normalized_citations_level1.parquet` - å¼•ç”¨å…³ç³»ï¼ˆçº§åˆ«1ï¼‰
- `sciscinet_authors.parquet` - ä½œè€…ä¿¡æ¯
- `sciscinet_author_details.parquet` - ä½œè€…è¯¦ç»†ä¿¡æ¯
- `sciscinet_affiliations.parquet` - æœºæž„ä¿¡æ¯
- `sciscinet_affl_assoc_affl.parquet` - æœºæž„å…³è”ä¿¡æ¯
- `sciscinet_fields.parquet` - ç ”ç©¶é¢†åŸŸä¿¡æ¯

## è½¬æ¢ Parquet ä¸º CSV

ä¸‹è½½å®ŒæˆåŽï¼Œå¯ä»¥å°† Parquet æ–‡ä»¶è½¬æ¢ä¸º CSVï¼š

```python
from download_dataset_api import HFDatasetAPIFetcher
from config import Config

fetcher = HFDatasetAPIFetcher(local_dir=Config.HF_DATASET_LOCAL_DIR)
fetcher.convert_parquets_to_csv(sample_size=None)  # None = å…¨éƒ¨è½¬æ¢
```

æˆ–åªè½¬æ¢æ ·æœ¬æ•°æ®ï¼š
```python
fetcher.convert_parquets_to_csv(sample_size=1000)  # åªè½¬æ¢å‰ 1000 è¡Œ
```

## æ•…éšœæŽ’é™¤

### é”™è¯¯: 401 Unauthorized
- âœ— é—®é¢˜: HF_TOKEN æ— æ•ˆæˆ–æœªè®¾ç½®
- âœ“ è§£å†³: ç¡®è®¤ token æœ‰æ•ˆä¸”å·²è®¾ç½®çŽ¯å¢ƒå˜é‡

### é”™è¯¯: ç½‘ç»œè¶…æ—¶
- âœ“ è§£å†³: é‡æ–°è¿è¡Œè„šæœ¬ï¼ˆæ”¯æŒæ–­ç‚¹ç»­ä¼ ï¼‰

### æ•°æ®ä¸å®Œæ•´
- âœ“ æŸ¥çœ‹æ—¥å¿—ç¡®è®¤æ‰€æœ‰æ–‡ä»¶æ˜¯å¦ä¸‹è½½å®Œæˆ
- âœ“ é‡æ–°è¿è¡Œè„šæœ¬ä¼šä»Žä¸Šæ¬¡ä¸­æ–­å¤„ç»§ç»­

## æ³¨æ„äº‹é¡¹

1. **æ•°æ®é‡å¾ˆå¤§**ï¼šSciSciNet-v2 æ€»å¤§å°å¯èƒ½è¶…è¿‡ 100GB
2. **éœ€è¦ç½‘ç»œè¿žæŽ¥**ï¼šå¿…é¡»ä¿æŒç½‘ç»œè¿žæŽ¥ç›´åˆ°ä¸‹è½½å®Œæˆ
3. **ç£ç›˜ç©ºé—´**ï¼šç¡®ä¿æœ‰è¶³å¤Ÿçš„ç£ç›˜ç©ºé—´å­˜å‚¨æ•°æ®
4. **æ—¶é—´**ï¼šæ ¹æ®ç½‘ç»œé€Ÿåº¦ï¼Œä¸‹è½½å¯èƒ½éœ€è¦æ•°å°æ—¶

## æ›´æ–°æ•°æ®èŽ·å–æ¨¡å—

ä¸‹è½½å®ŒæˆåŽï¼Œæ›´æ–° `data_fetcher.py` ä»¥ä½¿ç”¨æœ¬åœ°çš„ Parquet æ–‡ä»¶ï¼š

```python
def load_parquet(self, filename: str) -> pd.DataFrame:
    """åŠ è½½ Parquet æ–‡ä»¶"""
    filepath = Path(self.local_dir) / filename
    if filepath.exists():
        return pd.read_parquet(filepath)
    return pd.DataFrame()
```
